### EPIC-001: Enhanced Unified RAG with Dynamic Graph Memory (Graphiti) via BPMCP for Advanced Contextual Awareness

*   **Description:** Evolve the BPMCP to integrate **Graphiti** (planned to run as a dedicated service, potentially an MCP server, due to its Python base) as a dynamic, real-time knowledge graph layer, significantly enhancing existing RAG capabilities. This involves a unified gateway for agents to perform RAG operations using Bimba coordinates for foundational context, while leveraging Graphiti for immediate, evolving agent memory, dynamic relationship mapping, and awareness of real-time user interactions (e.g., chat context, UI canvas selections, **communicated via the AG-UI protocol**). The system will abstract complexities of interacting with Qdrant, Neo4j (Bimba & LightRAG), MongoDB, Notion, and the Graphiti service. A key aspect remains **harmonizing data schemas** across these systems (Bimba, LightRAG, MongoDB, Graphiti, Notion) and establishing clear processes for tandem updates, all while maintaining the **primacy of Bimba coordinates for contextual grounding.** Graphiti's integration will also consider its role within the evolving **6-subsystem backend architecture** (ref. friendly-file-backend README), ensuring it acts as a responsive memory layer supporting all agent functions. This enhanced RAG is fundamental for **streamlining context window generation in the epii analysis pipeline** by providing highly relevant, dynamically filtered information.
*   **Covered FRs:** FR1, FR2, FR5, and new requirements for dynamic memory, schema management, UI context awareness (via AG-UI), Graphiti service integration, and streamlined context generation.
*   **Goal:** Enable agents to easily fetch, synthesize, and act upon relevant information from diverse data sources (static, processed, dynamic/real-time, and UI-interactional via **AG-UI protocol**) based on precise spatio-semantic context (Bimba coordinates) and evolving agent/user interactions. The **Graphiti service** will be crucial for unifying user state (including chat/canvas focus from **AG-UI**), document insights, Bimba coordinate knowledge, agent-skill specific data, and semantic relationships into a single, highly accessible memory layer. This unified view, always anchored by **Bimba coordinates**, is essential for current analytical tasks, **informing potential Notion or Bimba updates,** and for future **Nara Mode** developments.
*   **Potential High-Level User Stories (Agent Perspective - Updated for Graphiti Integration, AG-UI & New Focus Areas):**
    *   "As an Epii Agent, I want to retrieve relevant information by querying the **Graphiti service** for dynamic, context-specific knowledge (including my current chat focus or UI selections **received via AG-UI**) linked to a Bimba coordinate, and supplement this with deeper document chunks from Qdrant/LightRAG, so that my analysis is grounded in both real-time interactions and processed information, **optimizing my context window.**"
    *   "As an Epii Agent, I want to identify related concepts by traversing the **Graphiti service's** knowledge graph (which reflects Bimba structure and dynamic user/document links, informed by **AG-UI context**) and then retrieve associated textual data from Qdrant, MongoDB, and Notion, so that I can build a comprehensive understanding **that might suggest updates to Notion or Bimba.**"
    *   "As an Epii Agent, I want to pass a query, a set of Bimba coordinates, and my current UI/chat context (via **AG-UI protocol**) to a unified RAG service that orchestrates retrieval from the **Graphiti service**, Qdrant/LightRAG, Neo4j (Bimba), MongoDB, and Notion, receiving a synthesized answer reflecting all knowledge layers, **which helps me generate concise and relevant responses or actions.**"